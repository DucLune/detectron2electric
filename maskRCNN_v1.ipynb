{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xz8KIETeQowm",
    "outputId": "4bb9ee47-485a-4e56-c596-a3f210eb996b"
   },
   "outputs": [],
   "source": [
    "#!pip install pyyaml==5.1\n",
    "#!pip install labelme\n",
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# Install detectron2 that matches the above pytorch version\n",
    "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
    "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-r6wyJKVQQrH"
   },
   "outputs": [],
   "source": [
    "# import some common libraries\n",
    "import random\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import detectron2\n",
    "import glob\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data.datasets import pascal_voc, register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import build_detection_test_loader,build_detection_train_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset, PascalVOCDetectionEvaluator\n",
    "from detectron2.utils.file_io import PathManager\n",
    "from detectron2.utils.logger import setup_logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87mFN4gmQ6LS",
    "outputId": "1d213b51-da0e-4eaa-ebc5-9c0e21761e18"
   },
   "outputs": [],
   "source": [
    "# 准备数据集合训练代码\n",
    "#!rm -r detectron2electric/\n",
    "#!git clone https://github.com/DucLune/detectron2electric.git\n",
    "#!cp /content/detectron2electric/traincode/* ./ -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4iFlrq4iQQrK"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "setup_logger()\n",
    "\n",
    "# 创建解析\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"detectron2 demo\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "# 添加参数\n",
    "# 使用Cloab等平台时请注意设置正确的root_dir为detectron2electric的路径\n",
    "parser.add_argument('--root_dir', type=str,\n",
    "                    default=\"/root/public_data/ElectricalComponent-MaskRCNN/detectron2electric\")\n",
    "parser.add_argument('--train_url', type=str,\n",
    "                    default=\"/root/public_data/model\", help='the path model saved')\n",
    "parser.add_argument('--dataset', type=str, default='/root/public_data/coco-lyq',\n",
    "                    help='the dataset dirname')\n",
    "parser.add_argument('--device', type=str, default='cuda',\n",
    "                    help='the training device')\n",
    "parser.add_argument('--num_classes', type=int, default=3,\n",
    "                    help='cfg.MODEL.ROI_HEADS.NUM_CLASSES ')\n",
    "\n",
    "# 解析参数\n",
    "args, unkown = parser.parse_known_args()\n",
    "os.chdir(args.root_dir)\n",
    "print(\"setting woring path to :\"+os.getcwd())\n",
    "from util import pictureUtils\n",
    "#pictureUtils.buildCocoDataset(\"Annotations\",os.path.join(args.dataset),[\"glue\",\"injection_hole\",\"pin_glue\"],0.7,0.3,0)\n",
    "register_coco_instances(\"mydataset_train\", {}, os.path.join(args.dataset,\"annotations\",\"train.json\"),\"SmallJPGImages\")\n",
    "register_coco_instances(\"mydataset_val\", {}, os.path.join(args.dataset,\"annotations\",\"val.json\"),\"SmallJPGImages\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3mPkhXMJQQrM",
    "outputId": "43ee329f-4b6c-4456-a5ab-64e5004eb806"
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# 定义模型并训练\n",
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\n",
    "    \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"../weights/model_final_a3ec72.pkl\")\n",
    "# cfg.MODEL.WEIGHTS = os.path.join(args.train_url, \"model_final.pth\")\n",
    "\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data import DatasetMapper   # the default mapper\n",
    "\n",
    "cfg.MODEL.DEVICE = args.device\n",
    "cfg.MODEL.RPN.NMS_THRESH = 0.7\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.5\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "cfg.DATASETS.TRAIN = (\"mydataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"mydataset_val\",)\n",
    "dataloader = build_detection_train_loader(cfg,\n",
    "   mapper=DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "    T.ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'),\n",
    "    T.RandomBrightness(0.9, 1.1),\n",
    "    T.RandomFlip(prob=0.5),\n",
    "    T.RandomCrop(\"absolute\", (320, 320))\n",
    "]))\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "# 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.MAX_ITER = 600\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "# faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "# only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = args.num_classes\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "cfg.OUTPUT_DIR = args.train_url\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "if args.device != 'cpu':\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Jy1RYxRQQrO"
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# 验证集验证\n",
    "\n",
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "# path to the model we just trained\n",
    "# 加载训练出来的权重\n",
    "cfg.MODEL.WEIGHTS = os.path.join(args.train_url, \"model_final.pth\")\n",
    "# 构建评估器\n",
    "evaluator = COCOEvaluator(\"mydataset_val\", output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"mydataset_val\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "# 输出模型在验证集上的性能指标\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`\n",
    "#model = trainer.build_model(cfg)\n",
    "#metrics = trainer.test(cfg, model, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QPr4sPNPR4X"
   },
   "outputs": [],
   "source": [
    "#!rm model/*.jpg\n",
    "#!mkdir model\n",
    "\n",
    "# 在测试集上测试，并保存图片\n",
    "import os\n",
    "demo = VisualizationDemo(cfg)\n",
    "#!rm model/*.jpg\n",
    "#!mkdir model\n",
    "filePath = os.path.join(args.data_url, args.dataset, \"test\")\n",
    "#list_data = os.listdir(filePath)\n",
    "list_data = [] \n",
    "for filename in list_data:\n",
    "    if filename.split('.')[1] == 'json':\n",
    "        continue\n",
    "    im = cv2.imread(os.path.join(filePath, filename))\n",
    "    predictions, visualized_output = demo.run_on_image(im)\n",
    "    visualized_output.save(os.path.join(args.train_url, filename))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "maskRCNN_glue_pin_inclined_v0.2.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "bd7d9e76bf3f8cb7ec8ecf65b13c7d9834da455c852c3f050893a48c10a1a2da"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
